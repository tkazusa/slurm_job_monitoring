# Slurm Job Resource Monitoring and Visualization

This repository contains two scripts:

1. **`monitor_job.sh`**: A Bash script to monitor the CPU, memory, and GPU resource usage of a specific job running on a Slurm cluster, and log the data to a CSV file.
2. **`visualize_resource_usage.py`**: A Python script to visualize the CPU, memory, and GPU resource usage data collected by the monitoring script.

## Requirements

### For `monitor_job.sh`:
- **Slurm workload manager** installed.
- Access to the following commands:
  - `sacct` (to monitor CPU and memory usage)
  - `squeue` (to check job status)
  - `nvidia-smi` (to monitor GPU usage, if applicable)
  
### For `visualize_resource_usage.py`:
  You can install the required Python libraries using pip:

  ```bash
  pip install pandas matplotlib
  ```

## Usage

### 1. Monitoring a Slurm Job (`monitor_job.sh`)

    The `monitor_job.sh` script monitors the resource usage of a specific Slurm job and logs the data to a CSV file in real-time. The script stops automatically when the job finishes.

#### Usage:

```bash
./monitor_job.sh <job_ID>
```

Replace `<job_ID>` with the Slurm job ID you want to monitor. The script will generate a CSV file named `job_<job_ID>_resource_usage.csv` containing the following columns:

- **Timestamp**: Date and time of the log entry.
- **MaxRSS_MB**: Maximum Resident Set Size (memory used) in MB.
- **MaxVMSize_MB**: Maximum Virtual Memory Size in MB.
- **AllocCPUs**: Number of allocated CPUs.
- **GPU_Utilization_%**: GPU utilization percentage (if applicable).
- **GPU_Mem_Used_MB**: GPU memory used in MB (if applicable).
- **GPU_Mem_Total_MB**: Total GPU memory available in MB (if applicable).

#### Example:

```bash
./monitor_job.sh 12345
```


### 2. Visualizing Resource Usage (`visualize_resource_usage.py`)

The `visualize_resource_usage.py` script reads the CSV file generated by `monitor_job.sh` and visualizes the CPU, memory, and GPU usage over time.

#### Usage:

```bash
python visualize_resource_usage.py
```

Before running the script, ensure that the `csv_file` variable inside the script points to the correct CSV file (e.g., `job_12345_resource_usage.csv`).

#### Example:

If your CSV file is named `job_12345_resource_usage.csv`, set the `csv_file` variable in the script like this:

```python
csv_file = 'job_12345_resource_usage.csv'
```

Then run:

```bash
python visualize_resource_usage.py
```

### Visualizations

The script will generate the following plots:

1. **CPU and Memory Usage Over Time**: Shows the maximum resident set size (MaxRSS), virtual memory size (MaxVMSize), and allocated CPUs over time.
2. **GPU Usage Over Time** (if applicable): Shows GPU utilization and memory usage over time if the job used a GPU.

## Example Logs

Here is an example of the CSV output generated by `monitor_job.sh`:

```
Timestamp, MaxRSS_MB, MaxVMSize_MB, AllocCPUs, GPU_Utilization_%, GPU_Mem_Used_MB, GPU_Mem_Total_MB
2024-10-05 14:05:01, 2000.00, 4096.00, 4, 70, 6000, 8000
2024-10-05 14:06:01, 2100.00, 4096.00, 4, 85, 6500, 8000
```

This CSV file can be visualized using the Python script.

## Customization

### Logging Frequency

By default, the `monitor_job.sh` script logs resource usage every 60 seconds. You can adjust this by modifying the `sleep 60` line in the script to your desired interval.


